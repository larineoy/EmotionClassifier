{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries \n",
    "# Keras\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "# sklearn\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "# Other\n",
    "import librosa\n",
    "import librosa.display\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import IPython.display as ipd  # To play sound in the notebook\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TESS = \"./Data/TESS/\"\n",
    "RAV = \"./Data/RAVDESS/\"\n",
    "SAVEE = \"./Data/SAVEE/\"\n",
    "CREMA = \"./Data/CREMA-D/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"./train_features.csv\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data.drop(['label','name'],axis=1))\n",
    "x_train = scaler.transform(train_data.drop(['label','name'],axis=1))\n",
    "\n",
    "pca = PCA(n_components = 75)\n",
    "train_pca = pca.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame(columns=['feature'])\n",
    "labels = pd.DataFrame(columns=['label'])\n",
    "names = pd.DataFrame(columns=['name'])\n",
    "    \n",
    "audio_sample_path = \"./output.wav\"\n",
    "x, sample_rate = librosa.load(audio_sample_path)\n",
    "print(sample_rate)\n",
    "# feature_set stores all features of the audio file\n",
    "feature_set = np.array([])\n",
    "\n",
    "# MFCC feature extraction\n",
    "# No. of MFCC Features = 40 (Default = 20)\n",
    "mfccs=np.mean(librosa.feature.mfcc(y=x, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "feature_set=np.hstack((feature_set, mfccs))\n",
    "print(mfccs.shape)\n",
    "## Chroma feature extraction\n",
    "# No. of Chroma Features = 12 (Always)\n",
    "stft=np.abs(librosa.stft(x))\n",
    "chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "feature_set=np.hstack((feature_set, chroma))\n",
    "print(chroma.shape)\n",
    "## Mel feature extraction\n",
    "# No. of Mel Features = 128 (Default = 128)\n",
    "mel=np.mean(librosa.feature.melspectrogram(y=x, sr=sample_rate).T,axis=0)\n",
    "feature_set=np.hstack((feature_set, mel))\n",
    "print(mel.shape)\n",
    "\n",
    "print(feature_set.shape)\n",
    "\n",
    "feature_set = np.reshape(feature_set, (1,-1))\n",
    "print(feature_set.shape)\n",
    "\n",
    "\n",
    "feature_set_pca = pca.transform(feature_set)\n",
    "print(\"After PCA shape:\", feature_set_pca.shape)\n",
    "\n",
    "feature_set_reshaped = feature_set_pca.reshape(-1, 75, 1)\n",
    "print(\"Reshaped for model input:\", feature_set_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_generator(train_path, test_path):\n",
    "        # Read the data from the saved CSV files\n",
    "        test_data = pd.read_csv(test_path)\n",
    "\n",
    "        # Perform standardization for better performance\n",
    "        scaler = StandardScaler()\n",
    "        x_test = scaler.transform(test_data,axis=1)\n",
    "\n",
    "        # Perform Principle Component Analysis (PCA) to change dimensions and remove co-relation\n",
    "        # No of PCA components = 75\n",
    "        pca = PCA(n_components = 75)\n",
    "        test_pca = pca.transform(x_test)\n",
    "        print(test_pca.shape) \n",
    "        \n",
    "        \n",
    "        # Expanding dimensions for CNN\n",
    "        x_train = np.expand_dims(train_pca, axis=2)\n",
    "        x_test = np.expand_dims(test_pca, axis=2)\n",
    "        \n",
    "        # Print train and test shapes\n",
    "        print(x_train.shape)\n",
    "        print(x_test.shape)\n",
    "        \n",
    "        return x_train, x_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"./saved_models/CNN with Feature Array.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(model.predict(feature_set_reshaped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "fs = 22050  # Sample rate\n",
    "seconds = 3  # Duration of recording\n",
    "\n",
    "myrecording = sd.rec(int(seconds * fs), samplerate=fs, channels=2)\n",
    "sd.wait()  # Wait until recording is finished\n",
    "write('output.wav', fs, myrecording)  # Save as WAV fil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_and_predict():\n",
    "\n",
    "    #Recording the audio from user's microphone\n",
    "    sample_rate = 22050  # Sample rate\n",
    "    seconds = 3  # Duration of recording\n",
    "\n",
    "    myrecording = sd.rec(int(seconds * sample_rate), samplerate=sample_rate, channels=2)\n",
    "    sd.wait()  # Wait until recording is finished\n",
    "    write('output.wav', fs, myrecording)\n",
    "\n",
    "    audio_sample_path = \"./output.wav\"\n",
    "    x, sample_rate = librosa.load(audio_sample_path)\n",
    "    print(sample_rate)\n",
    "    # feature_set stores all features of the audio file\n",
    "    feature_set = np.array([])\n",
    "\n",
    "    # MFCC feature extraction\n",
    "    # No. of MFCC Features = 40 (Default = 20)\n",
    "    mfccs=np.mean(librosa.feature.mfcc(y=x, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "    feature_set=np.hstack((feature_set, mfccs))\n",
    "    print(mfccs.shape)\n",
    "    ## Chroma feature extraction\n",
    "    # No. of Chroma Features = 12 (Always)\n",
    "    stft=np.abs(librosa.stft(x))\n",
    "    chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "    feature_set=np.hstack((feature_set, chroma))\n",
    "    print(chroma.shape)\n",
    "    ## Mel feature extraction\n",
    "    # No. of Mel Features = 128 (Default = 128)\n",
    "    mel=np.mean(librosa.feature.melspectrogram(y=x, sr=sample_rate).T,axis=0)\n",
    "    feature_set=np.hstack((feature_set, mel))\n",
    "    print(mel.shape)\n",
    "\n",
    "    print(feature_set.shape)\n",
    "\n",
    "    feature_set = np.reshape(feature_set, (1,-1))\n",
    "    print(feature_set.shape)\n",
    "\n",
    "\n",
    "    feature_set_pca = pca.transform(feature_set)\n",
    "    print(\"After PCA shape:\", feature_set_pca.shape)\n",
    "\n",
    "    feature_set_reshaped = feature_set_pca.reshape(-1, 75, 1)\n",
    "    print(\"Reshaped for model input:\", feature_set_reshaped.shape)\n",
    "\n",
    "    match_array = [\"female_angry\", \"female_calm\", \"female_disgust\", \"female_fearful\", \"female_happy\", \"female_neutral\", \"female_sad\", \"female_suprised\", \"male_angry\", \"male_calm\", \"male_disgust\", \"male_fearful\", \"male_happy\", \"male_neutral\", \"male_sad\", \"male_suprised\"]\n",
    "    print(match_array[np.argmax(model.predict(feature_set_reshaped))])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_and_predict()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
